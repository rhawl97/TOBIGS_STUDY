{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_trainset)  #데이터 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "torch.Size([100, 1, 28, 28])\n",
      "tensor([9, 3, 8, 0, 2, 6, 9, 8, 7, 3, 7, 1, 7, 3, 9, 0, 4, 9, 3, 1, 3, 4, 1, 0,\n",
      "        1, 2, 6, 3, 7, 9, 5, 0, 6, 4, 3, 0, 7, 3, 1, 7, 2, 3, 8, 8, 3, 0, 4, 8,\n",
      "        7, 4, 7, 2, 4, 2, 3, 7, 7, 6, 4, 3, 2, 6, 5, 2, 9, 1, 0, 9, 7, 6, 2, 0,\n",
      "        7, 4, 7, 3, 4, 6, 0, 3, 6, 4, 2, 3, 1, 4, 7, 0, 5, 2, 1, 5, 1, 5, 9, 0,\n",
      "        5, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader) #한 batch만 뽑아서 확인해보기 \n",
    "images, labels = train_iter.next() \n",
    "\n",
    "print(len(train_loader))\n",
    "print(images.shape)\n",
    "print(labels) #1차원 tensor인데 length 가 4인! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = {'input_size': 1*28*28,   #config #환경설정 #들어가야하는 input들 한번에 묶어놓은 것 \n",
    "       'hidden_size1':512,\n",
    "       'hidden_size2':256,\n",
    "       'hidden_size3':128,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':5,\n",
    "       'batch_size':100,\n",
    "       'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MnistModel_Yum(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(MnistModel_Yum, self).__init__()\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1']) #총 4개 layer!\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['hidden_size3'])\n",
    "        self.fc4 = nn.Linear(src['hidden_size3'], src['output_size']) #최종 length가 10인 tensor가 나옴\n",
    "                             \n",
    "        ## sequential layer\n",
    "        self.seq_fc = nn.Sequential(\n",
    "                            nn.Linear(src['input_size'], src['hidden_size1']),\n",
    "                            nn.Linear(src['hidden_size1'], src['hidden_size2']),\n",
    "                            nn.Linear(src['hidden_size2'], src['hidden_size3']),\n",
    "                            nn.Linear(src['hidden_size3'], src['output_size'])\n",
    "                            )   #하나의 layer로 묶음  #위랑 결과 같음!\n",
    "        \n",
    "        self.init_range = src['init_weight_range']\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range) #가중치 초기화 \n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc4.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        \n",
    "        for fc in self.seq_fc:\n",
    "            fc.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        \n",
    "    def forward(self, img): #layer가 4개 \n",
    "        x = img.view(img.shape[0], -1) #image shape 100, 1, 28, 28 중 100차원만 유지하고 나머지는 한 차원으로 묶어버리겠다\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        y = self.fc4(x)\n",
    "        #--------------------\n",
    "        \n",
    "        ## 4 lines above are identical to #sequencial로 써도 위와 같은 모델 \n",
    "        #  y = self.seq_fc(x)\n",
    "\n",
    "        return y #마지막 y는 length10짜리 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel_Yum(src) #init하는 부분 \n",
    "y = model(images) #forward부분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train / Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수 및 optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  #loss\n",
    "optimizer = optim.SGD(model.parameters(), #gradient를 어떤 방식으로 할건지 \n",
    "                      src['learning_rate'], \n",
    "                      momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 학습\n",
    "단순히 데이터를 반복시켜 네트워크와 optimizer의 입력으로 넘겨준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 53.6500\n",
      "Epoch [1/5], Step [200/600], Loss: 14.6841\n",
      "Epoch [1/5], Step [300/600], Loss: 10.2796\n",
      "Epoch [1/5], Step [400/600], Loss: 7.4278\n",
      "Epoch [1/5], Step [500/600], Loss: 6.1657\n",
      "Epoch [1/5], Step [600/600], Loss: 5.5989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▌                                  | 1/5 [02:15<09:02, 135.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/600], Loss: 4.6715\n",
      "Epoch [2/5], Step [200/600], Loss: 4.3907\n",
      "Epoch [2/5], Step [300/600], Loss: 3.8163\n",
      "Epoch [2/5], Step [400/600], Loss: 3.6536\n",
      "Epoch [2/5], Step [500/600], Loss: 3.3704\n",
      "Epoch [2/5], Step [600/600], Loss: 3.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████▏                         | 2/5 [04:45<06:59, 139.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/600], Loss: 2.9900\n",
      "Epoch [3/5], Step [200/600], Loss: 2.8956\n",
      "Epoch [3/5], Step [300/600], Loss: 3.0615\n",
      "Epoch [3/5], Step [400/600], Loss: 2.5494\n",
      "Epoch [3/5], Step [500/600], Loss: 2.3866\n",
      "Epoch [3/5], Step [600/600], Loss: 2.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▊                 | 3/5 [06:54<04:33, 136.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/600], Loss: 2.3115\n",
      "Epoch [4/5], Step [200/600], Loss: 2.3547\n",
      "Epoch [4/5], Step [300/600], Loss: 2.2709\n",
      "Epoch [4/5], Step [400/600], Loss: 2.2540\n",
      "Epoch [4/5], Step [500/600], Loss: 2.0345\n",
      "Epoch [4/5], Step [600/600], Loss: 2.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████▍        | 4/5 [08:40<02:07, 127.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/600], Loss: 1.9571\n",
      "Epoch [5/5], Step [200/600], Loss: 1.9825\n",
      "Epoch [5/5], Step [300/600], Loss: 1.7831\n",
      "Epoch [5/5], Step [400/600], Loss: 1.8317\n",
      "Epoch [5/5], Step [500/600], Loss: 1.8118\n",
      "Epoch [5/5], Step [600/600], Loss: 1.7474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 5/5 [10:24<00:00, 120.28s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  #빨간줄 \n",
    "\n",
    "model.init_weight()\n",
    "\n",
    "for epoch in tqdm(range(src['num_epochs'])):   #epoch 5번 \n",
    "    current_loss = 0.0\n",
    "#     model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(train_loader): #4개씩 묶여있는 사진들이 루프 한번만에!\n",
    "        # get the inputs\n",
    "        inputs, labels = data  #image에 사진이랑 클래스 있음 \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()  #0으로 초기화 \n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) #실제 사진과 확률의 차이\n",
    "        loss.backward()  #편미분 값들 계산\n",
    "        optimizer.step()  #계산한 값들로 update\n",
    "        \n",
    "        # print statistics\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step != 0:     # print every 1000 mini-batches\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %\n",
    "                  (epoch + 1, src['num_epochs'], step, len(train_loader)//100 * 100, current_loss / 100)) #누적합의 평균 \n",
    "            current_loss = 0.0  #12500개의 데이터 --> 1000번씩 찍으면 500이 남으므로 다음 epoch로 넘어가 loss가 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가\n",
    "학습 데이터셋을 이용해 총 5번 반복하면서 학습을 시켰다. 그러나 실제로 네트워크가 무엇인가를 배웠는지에 대하여 테스트를 해야한다.\n",
    "\n",
    "뉴럴 네트워크의 출력인 클래스 label을 예측하고 실제 데이터와 비교함으로써 테스트를 수행했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 6000 test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 6000 test images: %d %%' % (100 * correct / total))  #오~~~~ 이 정도면 만족쓰 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
